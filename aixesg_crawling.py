# -*- coding: utf-8 -*-
"""AIxESG_crawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I181L3FdtQVUchwVD3bqv6vWRoxNOm-C
"""

# ================================
# ESG 보고서 106개 일괄 분석 파이프라인 (Colab 1셀 버전)
# - PDF -> 텍스트 추출
# - AI/그린워싱/투명성 패턴 카운트 + 밀도화
# - PDF 파일명 ↔ ESG 엑셀(기업명) 자동 매칭(rapidfuzz)
# - 회귀모형(강건표준오차)로 AI, 그린워싱, 투명성 ↔ ESG관계 추정
# 출력물: pdf_text_metrics_extended.csv, auto_matched.csv, review_needed.csv, modeling_summary.txt
# =================================

# 0) 설치
!pip -q install pymupdf regex rapidfuzz pandas tqdm statsmodels

# 1) 옵션: 데이터 불러오기 방법 둘 중 하나를 사용
#   A안) 여러 PDF를 로컬에서 수동 업로드
#   B안) Google Drive 마운트 후 지정 폴더 사용 (권장: "경영컨설팅 자료" 폴더)
USE_GOOGLE_DRIVE = True  # True면 B안(드라이브), False면 A안(수동 업로드)

import os, re, io, fitz, pandas as pd, numpy as np
from tqdm import tqdm
from rapidfuzz import process, fuzz

# 2) ESG 등급 엑셀 파일 준비
#   - Colab 파일탐색기에서 esg_master_final.xlsx를 업로드하거나,
#     드라이브 경로로 지정해 주세요.
ESG_EXCEL_PATH = None  # 예) "/content/drive/MyDrive/경영컨설팅 자료/esg_master_final.xlsx"
DEFAULT_ESG_EXCEL_NAME = "esgc.xlsx"  # 업로드만 했다면 파일명으로 찾음

# 3) 데이터 경로 설정
if USE_GOOGLE_DRIVE:
    from google.colab import drive
    drive.mount('/content/drive')
    # 네가 말한 폴더명 기본값: "경영컨설팅 자료"
    DATA_DIR = "/content/drive/MyDrive/경영컨설팅 자료"
    PDF_DIR = DATA_DIR  # PDF들이 이 폴더에 모두 있다고 가정
else:
    # A안: 수동 업로드
    from google.colab import files
    print("여러 PDF를 한 번에 선택해서 업로드하세요.")
    uploaded = files.upload()  # 여러 PDF/엑셀 동시 업로드 가능
    PDF_DIR = "/content/pdfs"
    os.makedirs(PDF_DIR, exist_ok=True)
    # 업로드된 파일 중 PDF는 /content/pdfs 로 이동
    for nm in uploaded:
        if nm.lower().endswith(".pdf"):
            os.replace(nm, os.path.join(PDF_DIR, nm))
    # ESG 엑셀 경로 자동 추정
    if ESG_EXCEL_PATH is None and DEFAULT_ESG_EXCEL_NAME in uploaded:
        ESG_EXCEL_PATH = DEFAULT_ESG_EXCEL_NAME

# 4) ESG 엑셀 경로 최종 확정
if ESG_EXCEL_PATH is None:
    # 드라이브 모드일 때 폴더에 파일이 있으면 자동 선택
    cand = os.path.join(PDF_DIR, DEFAULT_ESG_EXCEL_NAME)
    if os.path.exists(cand):
        ESG_EXCEL_PATH = cand
    else:
        # 루트에도 있는지 확인
        cand2 = "/content/" + DEFAULT_ESG_EXCEL_NAME
        ESG_EXCEL_PATH = cand2 if os.path.exists(cand2) else None

if ESG_EXCEL_PATH is None or not os.path.exists(ESG_EXCEL_PATH):
    raise FileNotFoundError(
        "ESG 등급 엑셀 파일을 찾을 수 없어요. 'esg_master_final.xlsx'를 업로드하거나 ESG_EXCEL_PATH를 경로로 지정해 주세요."
    )

# 5) PDF 목록 수집
all_files = os.listdir(PDF_DIR)
pdfs = [os.path.join(PDF_DIR, f) for f in all_files if f.lower().endswith(".pdf")]
if len(pdfs) == 0:
    raise FileNotFoundError("PDF를 찾을 수 없어요. 폴더(또는 업로드)에 PDF가 있는지 확인해 주세요.")

print(f"발견된 PDF 개수: {len(pdfs)}")

# 6) ESG 엑셀 로드 (기업명/등급 컬럼 자동 추정)
esg = pd.read_excel(ESG_EXCEL_PATH)

def find_col(df, candidates):
    cols = list(df.columns)
    for c in candidates:
        if c in cols:
            return c
    # 스페이스 제거, 소문자 비교
    norm_map = {re.sub(r"\s","",str(x)).lower(): x for x in cols}
    for c in candidates:
        k = re.sub(r"\s","",c).lower()
        if k in norm_map:
            return norm_map[k]
    return None

company_col = find_col(esg, ["기업명","회사명","종목명","company","Company"])
esg_col     = find_col(esg, ["ESG등급","esg_grade","통합등급","ESG","등급"])

if company_col is None:
    raise KeyError("엑셀에서 기업명 컬럼을 찾지 못했어요. (예: '기업명', 'company')")
if esg_col is None:
    raise KeyError("엑셀에서 ESG 등급 컬럼을 찾지 못했어요. (예: 'ESG등급', 'esg_grade')")

# 등급 숫자화 매핑 (필요 시 조정)
ESG_MAP = {"A+":5, "A":4, "B+":3, "B":2, "C":1}
esg["_ESG_SCORE"] = esg[esg_col].astype(str).str.strip().str.upper().map(ESG_MAP)

# 7) 키워드 패턴 (확장판)
AI_PATTERNS = [
    r"\bAI\b", r"\bA\.I\.\b", r"인공지능", r"머신\s*러닝", r"머신러닝", r"딥\s*러닝", r"딥러닝",
    r"자연어\s*처리", r"자연어처리", r"강화\s*학습", r"강화학습", r"컴퓨터\s*비전", r"컴퓨터비전",
    r"\bML\b", r"\bDL\b", r"예측\s*모델", r"추천\s*시스템", r"분류\s*모델", r"생성\s*모델",
    r"음성\s*인식", r"이미지\s*분석", r"문서\s*요약", r"자동\s*요약",
    r"생성형\s*AI", r"생성\s*AI", r"\bGen\s*AI\b", r"\bGenAI\b", r"\bLLM\b",
    r"대규모\s*언어\s*모델", r"챗\s*GPT", r"챗GPT", r"대화형\s*AI", r"프롬프트\s*엔지니어링",
    r"지능형\s*시스템", r"지능형\s*공정", r"스마트\s*팩토리", r"스마트팩토리",
    r"지능형\s*자동화", r"하이퍼\s*오토메이션", r"예측\s*정비", r"이상징후\s*탐지",
    r"디지털\s*전환", r"디지털\s*트랜스포메이션", r"데이터\s*기반", r"데이터\s*분석",
    r"의사결정\s*지원\s*시스템", r"분석\s*엔진", r"분석\s*플랫폼", r"모델\s*고도화",
    r"AI\s*거버넌스", r"AI\s*윤리", r"AI\s*리스크", r"AI\s*센터", r"AI\s*조직",
    r"AI\s*플랫폼", r"AI\s*솔루션", r"AI\s*도입", r"AI\s*활용", r"AI\s*전략"
]

AMBIGUOUS_PATTERNS = [
    r"지속적(?:으로)?\s*노력", r"노력하고\s*있", r"최대한\s*노력", r"노력해\s*나가",
    r"지속적인\s*개선", r"향상시키기\s*위해", r"강화하겠", r"추진하고\s*있", r"추진\s*중",
    r"진행\s*중", r"도입을\s*검토", r"검토할\s*예정", r"향후", r"앞으로", r"추후",
    r"지향하겠", r"도모하겠", r"확대해\s*나가겠", r"강화해\s*나가겠",
    r"지속\s*추진", r"지속\s*강화", r"추진\s*예정", r"목표로\s*하겠", r"확대\s*계획",
    r"가능한\s*범위", r"현황을\s*고려", r"상황에\s*따라", r"필요에\s*따라",
    r"여건이\s*허락하는\s*한", r"관련\s*법규를\s*준수", r"기준에\s*맞춰", r"요구사항에\s*따라"
]

OVERPOS_PATTERNS = [
    r"탁월한", r"선도적", r"세계\s*최고(?:\s*수준)?", r"세계적\s*수준", r"혁신적",
    r"우수한", r"모범적", r"글로벌\s*리더", r"업계\s*최고", r"최고\s*수준의",
    r"탁월한\s*성과", r"뛰어난", r"차별화된", r"선진적", r"세계\s*최초", r"독보적",
    r"대표적", r"압도적", r"친환경\s*선도기업", r"그린\s*리더", r"ESG\s*리더십",
    r"지속가능경영의\s*모범", r"책임경영\s*선도", r"사회적\s*책임\s*완수",
    r"윤리경영\s*실천기업", r"환경\s*친화적", r"친환경적", r"탄소중립\s*선도",
    r"녹색경영\s*선도", r"모두가\s*행복한", r"더\s*나은\s*미래", r"함께\s*성장",
    r"상생", r"공존", r"아름다운", r"희망찬", r"따뜻한", r"의미있는\s*변화"
]

DISCLOSURE_PATTERNS = [
    r"\b\d{1,3}(\.\d+)?\s*%(\b|)", r"\b\d{1,3}(,\d{3})+\b", r"\b\d+(\.\d+)?\s*tCO2e?\b",
    r"스코프\s*1", r"스코프\s*2", r"스코프\s*3", r"Scope\s*1", r"Scope\s*2", r"Scope\s*3",
    r"재생에너지\s*비율", r"재생\s*전력", r"에너지\s*사용량", r"온실가스\s*배출량",
    r"폐기물\s*발생량", r"매립\s*감소", r"수자원\s*사용량", r"산재\s*발생률",
    r"여성\s*임원\s*비율", r"이사회\s*독립성", r"사외이사\s*비중", r"감사위원회",
    r"공급망\s*감사", r"인권\s*실사", r"협력사\s*평가"
]

STANDARD_PATTERNS = [
    r"GRI\s*Standards?", r"GRI\s*지표", r"SASB", r"TCFD", r"ISSB", r"IFRS\s*S1", r"IFRS\s*S2",
    r"CDP", r"UNGC", r"SDGs?", r"ISO\s*14001", r"ISO\s*45001", r"ISO\s*50001"
]

ASSURANCE_PATTERNS = [
    r"외부\s*검증", r"제3자\s*검증", r"검증\s*의견", r"한영회계법인", r"삼일회계법인",
    r"삼정KPMG", r"딜로이트", r"ISAE\s*3000", r"AA1000AS", r"LRQA", r"DNV", r"Bureau\s*Veritas",
    r"KSA\s*3000"
]
import regex as rx
def compile_patterns(lst):
    return [rx.compile(p, rx.IGNORECASE) for p in lst]
AI_RE   = compile_patterns(AI_PATTERNS)
AMB_RE  = compile_patterns(AMBIGUOUS_PATTERNS)
OP_RE   = compile_patterns(OVERPOS_PATTERNS)
DISC_RE = compile_patterns(DISCLOSURE_PATTERNS)
STD_RE  = compile_patterns(STANDARD_PATTERNS)
ASSU_RE = compile_patterns(ASSURANCE_PATTERNS)

SPLIT = rx.compile(r"(?<=[.!?]|다\.)\s+|\n+")

def extract_text(path):
    txt = ""
    try:
        doc = fitz.open(path)
        for pg in doc:
            txt += pg.get_text("text") + "\n"
        doc.close()
    except Exception as e:
        print("❌ 텍스트 추출 실패:", path, e)
    return txt

def count_hits(text, comp_list):
    return sum(len(c.findall(text)) for c in comp_list)

def rough_name_from_path(p):
    base = os.path.splitext(os.path.basename(p))[0]
    base = rx.sub(r"(20\d{2}|ESG|보고서|통합|지속가능|sustainability|report)", "", base, flags=rx.IGNORECASE)
    base = rx.sub(r"[_\-\s]+", "", base)
    return base

# 8) PDF 텍스트 분석
records = []
for p in tqdm(pdfs):
    txt = extract_text(p)
    sentences = [s.strip() for s in SPLIT.split(txt) if s.strip()]
    wc = max(1, len(txt.split()))
    sc = max(1, len(sentences))
    ai   = count_hits(txt, AI_RE)
    amb  = count_hits(txt, AMB_RE)
    op   = count_hits(txt, OP_RE)
    disc = count_hits(txt, DISC_RE)
    std  = count_hits(txt, STD_RE)
    assu = count_hits(txt, ASSU_RE)

    ai_density = ai / (wc/1000.0)
    gw_density = (amb + op) / sc
    tr_density = (disc + std + assu) / sc

    records.append({
        "pdf_path": p,
        "name_key": rough_name_from_path(p),
        "word_count": wc, "sent_count": sc,
        "ai_hits": ai, "ambiguous_hits": amb, "overpos_hits": op,
        "disclosure_hits": disc, "standard_hits": std, "assurance_hits": assu,
        "AI_Density": ai_density, "GW_Density": gw_density, "TR_Density": tr_density
    })

metrics = pd.DataFrame(records)
metrics.to_csv("pdf_text_metrics_extended.csv", index=False)

# ============================================
# ESG 텍스트 지표 시각화 원샷 코드 (복붙용)
# - CSV/XLSX 로딩 → 지표 점검/결측 처리 → 시각화/저장
# - 'metrics' DF가 이미 있으면 파일 로딩 생략
# ============================================

import os, math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 1) 파일 경로만 바꿔주세요 (CSV나 XLSX 둘 다 OK)
# 예) "/content/pdf_text_metrics_no_match.csv"  또는  "/content/metrics.xlsx"
FILE_PATH = "/content/pdf_text_metrics_extended.csv" # <- 여기만 수정

# 2) 데이터 준비: 이미 'metrics' DF가 있으면 그걸 쓰고, 없으면 파일에서 로딩
try:
    metrics
    df = metrics.copy()
except NameError:
    if not os.path.exists(FILE_PATH):
        raise FileNotFoundError(f"파일을 찾을 수 없습니다: {FILE_PATH}")
    ext = os.path.splitext(FILE_PATH)[1].lower()
    if ext in [".xlsx", ".xls"]:
        df = pd.read_excel(FILE_PATH)
    elif ext in [".csv", ".txt"]:
        df = pd.read_csv(FILE_PATH)
    else:
        raise ValueError("지원하지 않는 파일 형식입니다. csv 또는 xlsx를 사용해주세요.")

# 3) 필수 컬럼 점검 및 보정
need_cols = ["AI_Density","GW_Density","TR_Density"]
missing = [c for c in need_cols if c not in df.columns]
if missing:
    raise KeyError(f"필수 컬럼이 없습니다: {missing}  (AI_Density, GW_Density, TR_Density 필요)")

# 숫자 변환 & 결측 처리
for c in ["AI_Density","GW_Density","TR_Density","ESG_TextScore"]:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce")

# ESG_TextScore이 없으면 자동 계산: TR - GW
if "ESG_TextScore" not in df.columns:
    df["ESG_TextScore"] = df["TR_Density"] - df["GW_Density"]

# 결측 제거한 모델용 DF
use = df.dropna(subset=["AI_Density","GW_Density","TR_Density","ESG_TextScore"]).copy()
print(f"사용 표본 수: {len(use)} / 전체 {len(df)}")

# 4) 요약 통계 & 상관 행렬
desc = use[["AI_Density","GW_Density","TR_Density","ESG_TextScore"]].describe()
corr = use[["AI_Density","GW_Density","TR_Density","ESG_TextScore"]].corr()

print("\n[요약 통계]\n", desc)
print("\n[상관 행렬]\n", corr)

# 저장
OUT_DIR = "/content" if os.path.isdir("/content") else "."
desc.to_csv(os.path.join(OUT_DIR, "summary_stats.csv"))
corr.to_csv(os.path.join(OUT_DIR, "correlation_matrix.csv"))

# 5) 그리기 도우미: 산점도 + 단순회귀선 (matplotlib만 사용, 색상 지정 없음)
def scatter_with_fit(x, y, xlab, ylab, title, outname):
    plt.figure()
    plt.scatter(x, y)
    try:
        # 1차 회귀선
        m, b = np.polyfit(x, y, 1)
        x_line = np.linspace(np.nanmin(x), np.nanmax(x), 100)
        y_line = m * x_line + b
        plt.plot(x_line, y_line)
    except Exception:
        pass
    plt.xlabel(xlab)
    plt.ylabel(ylab)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, outname), dpi=150)
    plt.show()

# 6) 산점도들 (AI/GW/TR vs ESG_TextScore)
scatter_with_fit(
    use["AI_Density"].values, use["ESG_TextScore"].values,
    "AI_Density (per 1k words)", "ESG_TextScore (TR - GW)",
    "AI vs ESG_TextScore", "plot_ai_vs_esgtext.png"
)

scatter_with_fit(
    use["GW_Density"].values, use["ESG_TextScore"].values,
    "Greenwashing Density (per sentence)", "ESG_TextScore",
    "Greenwashing vs ESG_TextScore", "plot_gw_vs_esgtext.png"
)

scatter_with_fit(
    use["TR_Density"].values, use["ESG_TextScore"].values,
    "Transparency Density (per sentence)", "ESG_TextScore",
    "Transparency vs ESG_TextScore", "plot_tr_vs_esgtext.png"
)

# 7) 히스토그램 & 박스플롯 (분포 확인)
for col in ["AI_Density","GW_Density","TR_Density","ESG_TextScore"]:
    plt.figure()
    plt.hist(use[col].dropna().values, bins=30)
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.title(f"Histogram: {col}")
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, f"hist_{col}.png"), dpi=150)
    plt.show()

    plt.figure()
    plt.boxplot(use[col].dropna().values, vert=True)
    plt.ylabel(col)
    plt.title(f"Boxplot: {col}")
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, f"box_{col}.png"), dpi=150)
    plt.show()

# 8) 상관 히트맵 (matplotlib imshow)
plt.figure()
mat = corr.values
im = plt.imshow(mat)
plt.xticks(range(mat.shape[1]), corr.columns, rotation=45, ha="right")
plt.yticks(range(mat.shape[0]), corr.index)
plt.title("Correlation Heatmap")
plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR, "correlation_heatmap.png"), dpi=150)
plt.show()

# 9) AI 강도 분위별 ESG_TextScore 평균 막대 (Q1~Q4)
try:
    q = pd.qcut(use["AI_Density"], 4, labels=["Q1(low)","Q2","Q3","Q4(high)"])
    grp = use.groupby(q)["ESG_TextScore"].mean()
    plt.figure()
    plt.bar(grp.index.astype(str), grp.values)
    plt.xlabel("AI_Density Quartile")
    plt.ylabel("Mean ESG_TextScore")
    plt.title("ESG_TextScore by AI Quartile")
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, "bar_esgtext_by_ai_quartile.png"), dpi=150)
    plt.show()
except Exception:
    pass

print("\n✅ 완성! 저장 위치:", OUT_DIR)
print("- summary_stats.csv / correlation_matrix.csv")
print("- plot_ai_vs_esgtext.png / plot_gw_vs_esgtext.png / plot_tr_vs_esgtext.png")
print("- hist_*.png / box_*.png / correlation_heatmap.png / bar_esgtext_by_ai_quartile.png (가능 시)")

